{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18508\\3271525685.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('data/X_train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('data/X_train.csv')\n",
    "Y_train = pd.read_csv('data/y_train.csv')\n",
    "test_data = pd.read_csv('data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18508\\2172149830.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data['livingRoom'].replace({'#NAME?': 2}, inplace=True)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_18508\\2172149830.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['livingRoom'].replace({'#NAME?': 2}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_construction_time_data(construction_time_series):\n",
    "    def process_construction_time(x):\n",
    "        try:\n",
    "            year = int(x)\n",
    "            if 1900 <= year <= 2024:  \n",
    "                return year\n",
    "            else:\n",
    "                return np.nan\n",
    "        except ValueError:\n",
    "            return np.nan  # Trả về NaN cho các giá trị không phải số hoặc số không hợp lệ\n",
    "\n",
    "    # Áp dụng hàm xử lý\n",
    "    cleaned_series = construction_time_series.apply(process_construction_time)\n",
    "    \n",
    "    # Tìm giá trị phổ biến nhất (mode) trong các giá trị hợp lệ\n",
    "    mode_value = cleaned_series.mode().iloc[0]\n",
    "    \n",
    "    # Điền các giá trị NaN bằng giá trị phổ biến nhất\n",
    "    cleaned_series = cleaned_series.fillna(mode_value)\n",
    "    \n",
    "    return cleaned_series.astype(int)  # Chuyển đổi tất cả giá trị về kiểu int\n",
    "\n",
    "# Sử dụng hàm\n",
    "train_data['constructionTime'] = clean_construction_time_data(train_data['constructionTime'])\n",
    "test_data['constructionTime'] = clean_construction_time_data(test_data['constructionTime'])\n",
    "train_data['livingRoom'].replace({'#NAME?': 2}, inplace=True)\n",
    "test_data['livingRoom'].replace({'#NAME?': 2}, inplace=True)\n",
    "\n",
    "# We will find distance agnaist each lat and lng from Beijing (lat:39.916668,lon:116.383331)\n",
    "def distance(lat2, lon2,lat1=39.916668,lon1=116.383331): \n",
    "      \n",
    "    # The math module contains a function named \n",
    "    # radians which converts from degrees to radians. \n",
    "    lon1 = radians(lon1) \n",
    "    lon2 = radians(lon2) \n",
    "    lat1 = radians(lat1) \n",
    "    lat2 = radians(lat2) \n",
    "       \n",
    "    # Haversine formula  \n",
    "    dlon = lon2 - lon1  \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "  \n",
    "    c = 2 * asin(sqrt(a))  \n",
    "     \n",
    "    # Radius of earth in kilometers. Use 3956 for miles \n",
    "    r = 6371\n",
    "       \n",
    "    # calculate the result \n",
    "    return(c * r) \n",
    "\n",
    "train_data['distance'] = train_data.apply(lambda x: distance (x['Lat'],x['Lng']),axis=1)\n",
    "train_data['building_age'] = 2024 - train_data['constructionTime']\n",
    "\n",
    "test_data['distance'] = test_data.apply(lambda x: distance (x['Lat'],x['Lng']),axis=1)\n",
    "test_data['building_age'] = 2024 - test_data['constructionTime']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  20,  22,  25,  17,  24,  30,  16,  21,  13,  18,  26,  14,\n",
       "        35,  19,  32,  39,  37,  15,  29,  34,  27,  11,  36,  43,  45,\n",
       "        23,  31,  38,  49,  33,  40,  44,  12,  28,  60,  41,   9,  58,\n",
       "        10,  54,  48,  59,  66,  68,  46,  69,  61,  50,  47,  64,  57,\n",
       "        51,  70,  56,  67,   8,  62,  53,  52,  65,  71,  63,  74,  90,\n",
       "        91,  72, 110,  55,  80])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in ra giá trị unique của từng cột\n",
    "train_data['building_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                       int64\n",
       "Lng                    float64\n",
       "Lat                    float64\n",
       "tradeTime               object\n",
       "followers                int64\n",
       "square                 float64\n",
       "livingRoom              object\n",
       "drawingRoom             object\n",
       "kitchen                  int64\n",
       "bathRoom                object\n",
       "floor                   object\n",
       "buildingType           float64\n",
       "constructionTime         int32\n",
       "renovationCondition      int64\n",
       "buildingStructure        int64\n",
       "ladderRatio            float64\n",
       "elevator               float64\n",
       "fiveYearsProperty      float64\n",
       "subway                 float64\n",
       "district                 int64\n",
       "communityAverage       float64\n",
       "distance               float64\n",
       "building_age             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tradeTime: ['2012-11-12' '2014-11-29' '2015-02-05' ... '2010-02-26' '2010-03-05'\n",
      " '2010-04-11']\n",
      "\n",
      "livingRoom: ['2' '1' '3' '4' '5' '6' '9' '7' '0' '8' 2]\n",
      "\n",
      "drawingRoom: ['1' '2' '0' '3' '4' '中 16' '中 24' '中 14' '底 28' '中 15' '底 11' '5' '低 15'\n",
      " '中 22' '中 6' '低 6' '高 14' '底 20' '低 16' '高 12']\n",
      "\n",
      "bathRoom: ['1' '2' '3' '0' '4' '5' '6' '2006' '未知' '2003' '2005' 1 2 3 0 5 4 2003\n",
      " 2005 6 2000 1990 2006 1994 7 2004 1996 2011]\n",
      "\n",
      "floor: ['顶 5' '高 24' '高 12' '低 24' '中 6' '中 14' '底 5' '低 22' '顶 6' '中 9' '低 18'\n",
      " '中 17' '低 19' '中 11' '高 23' '高 32' '中 18' '底 6' '低 6' '中 12' '低 7' '低 20'\n",
      " '低 14' '中 8' '高 10' '底 7' '高 6' '底 22' '低 28' '底 18' '未知 6' '顶 26' '高 7'\n",
      " '中 5' '高 9' '中 16' '高 16' '中 21' '低 21' '低 11' '中 31' '高 18' '高 15'\n",
      " '底 28' '低 17' '低 30' '高 27' '底 13' '底 4' '低 12' '高 25' '中 19' '低 16'\n",
      " '低 29' '高 22' '顶 4' '中 7' '顶 22' '中 15' '中 22' '底 11' '顶 16' '中 10'\n",
      " '中 28' '低 9' '底 10' '高 26' '顶 14' '顶 9' '中 29' '顶 17' '低 26' '高 11'\n",
      " '高 30' '低 25' '高 17' '低 10' '顶 7' '低 32' '中 13' '中 25' '底 26' '中 27'\n",
      " '顶 18' '中 32' '低 15' '顶 20' '中 20' '高 14' '顶 24' '中 24' '低 27' '底 20'\n",
      " '底 1' '中 23' '高 19' '底 12' '高 20' '高 28' '高 31' '高 13' '顶 11' '底 16'\n",
      " '顶 15' '中 26' '中 4' '顶 13' '底 15' '高 21' '低 13' '高 34' '底 21' '顶 21'\n",
      " '底 14' '顶 12' '底 3' '低 8' '高 29' '低 23' '底 9' '未知 11' '顶 23' '顶 10'\n",
      " '底 25' '顶 30' '顶 8' '中 30' '未知 26' '未知 4' '未知 5' '低 31' '未知 7' '未知 16'\n",
      " '低 33' '顶 25' '高 33' '未知 18' '顶 28' '中 34' '顶 27' '未知 3' '高 8' '底 17'\n",
      " '顶 19' '顶 2' '中 33' '未知 14' '顶 3' '顶 29' '底 24' '低 42' '未知 25' '低 3'\n",
      " '底 23' '顶 34' '未知 24' '底 19' '底 8' '未知 23' '中 42' '低 34' '底 30' '低 37'\n",
      " '未知 20' '未知 31' '未知 12' '未知 21' '未知 10' '底 29' '底 2' '未知 22' '底 31'\n",
      " '底 27' '底 32' '未知 8' '顶 32' '高 36' '未知 28' '中 36' '未知 19' '未知 27' '未知 13'\n",
      " '未知 17' '钢混结构' '未知 15' '底 33' '顶 33' '未知 29' '高 37' '底 34' '未知 9' '未知 30'\n",
      " '高 42' '低 63' '顶 31' '中 37' '混合结构' '低 36' '中 35' '低 2' '低 35' '中 57']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in range(train_data.shape[1]):\n",
    "    if(train_data.iloc[:,row].dtype==\"O\"):\n",
    "        print(\"{}: {}\\n\".format(train_data.columns[row],train_data.iloc[:,row].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# in ra giá trị unique của từng cột\n",
    "print(train_data['buildingStructure'].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_building_type_data(building_type_series):\n",
    "    def process_building_type(x):\n",
    "        if pd.isna(x):\n",
    "            return 'Unknown'\n",
    "        elif isinstance(x, (int, float)):\n",
    "            if x == 1 or x == 1.0:\n",
    "                return 'Tower'\n",
    "            elif x == 2 or x == 2.0:\n",
    "                return 'Bungalow'\n",
    "            elif x == 3 or x == 3.0:\n",
    "                return 'Tower and Plate'\n",
    "            elif x == 4 or x == 4.0:\n",
    "                return 'Plate'\n",
    "            elif 0 < x < 1:  # Handling decimal values\n",
    "                return 'Plate'\n",
    "            else:\n",
    "                return 'Plate'\n",
    "        else:\n",
    "            return str(x)  # Keep existing string values\n",
    "\n",
    "    cleaned_series = building_type_series.apply(process_building_type)\n",
    "    \n",
    "    return cleaned_series\n",
    "\n",
    "# Sử dụng hàm\n",
    "train_data['buildingType'] = clean_building_type_data(train_data['buildingType'])\n",
    "test_data['buildingType'] = clean_building_type_data(test_data['buildingType'])\n",
    "def clean_floor_data(floor_series):\n",
    "    def process_floor(x):\n",
    "        x = str(x)\n",
    "        if x == '结构':\n",
    "            return 6  \n",
    "        else:\n",
    "            return x[-2:].strip()  # lấy 2 ký tự cuối và loại bỏ khoảng trắng\n",
    "    \n",
    "    cleaned_series = floor_series.apply(process_floor)\n",
    "    \n",
    "    # Chuyển đổi thành số nếu có thể\n",
    "    cleaned_series = pd.to_numeric(cleaned_series, errors='coerce')\n",
    "    \n",
    "    # Điền giá trị NaN bằng mode\n",
    "    median_value = cleaned_series.mode().iloc[0]\n",
    "    cleaned_series = cleaned_series.fillna(median_value)\n",
    "    \n",
    "    return cleaned_series\n",
    "\n",
    "# Sử dụng hàm\n",
    "train_data['floor'] = clean_floor_data(train_data['floor'])\n",
    "test_data['floor'] = clean_floor_data(test_data['floor'])\n",
    "\n",
    "def clean_bathroom_data(bathroom_series):\n",
    "    # Chuyển đổi series thành chuỗi\n",
    "    bathroom_series = bathroom_series.astype(str)\n",
    "    \n",
    "    # Hàm để xử lý từng giá trị\n",
    "    def process_value(x):\n",
    "        try:\n",
    "            # Chuyển đổi thành số nguyên\n",
    "            value = int(float(x))\n",
    "            # Kiểm tra xem giá trị có nằm trong khoảng hợp lý không (0-6)\n",
    "            if 0 <= value <= 6:\n",
    "                return value\n",
    "            else:\n",
    "                return np.nan\n",
    "        except ValueError:\n",
    "            # Nếu không thể chuyển đổi thành số, trả về NaN\n",
    "            return np.nan\n",
    "    \n",
    "    # Áp dụng hàm xử lý cho series\n",
    "    cleaned_series = bathroom_series.apply(process_value)\n",
    "    \n",
    "    # Điền giá trị thiếu bằng median\n",
    "    median_value = cleaned_series.mode().iloc[0]\n",
    "    cleaned_series = cleaned_series.fillna(median_value)\n",
    "    \n",
    "    return cleaned_series\n",
    "\n",
    "# Sử dụng hàm\n",
    "train_data['bathRoom'] = clean_bathroom_data(train_data['bathRoom'])\n",
    "test_data['bathRoom'] = clean_bathroom_data(test_data['bathRoom'])\n",
    "\n",
    "def clean_drawing_room_data(drawing_room_series):\n",
    "    def process_drawing_room(x):\n",
    "        x = str(x).lower()\n",
    "        if x.isdigit():\n",
    "            return int(x)\n",
    "        else:\n",
    "            parts = x.split()\n",
    "            if len(parts) == 2 and parts[1].isdigit():\n",
    "                return int(parts[1])\n",
    "            else:\n",
    "                return np.nan\n",
    "\n",
    "    cleaned_series = drawing_room_series.apply(process_drawing_room)\n",
    "    \n",
    "    # Điền giá trị NaN bằng median\n",
    "    median_value = cleaned_series.mode().iloc[0]\n",
    "    cleaned_series = cleaned_series.fillna(median_value)\n",
    "    \n",
    "    return cleaned_series\n",
    "\n",
    "# Sử dụng hàm\n",
    "train_data['drawingRoom'] = clean_drawing_room_data(train_data['drawingRoom'])\n",
    "test_data['drawingRoom'] = clean_drawing_room_data(test_data['drawingRoom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Lng', 'Lat', 'tradeTime', 'followers', 'square', 'livingRoom',\n",
       "       'drawingRoom', 'kitchen', 'bathRoom', 'floor', 'buildingType',\n",
       "       'constructionTime', 'renovationCondition', 'buildingStructure',\n",
       "       'ladderRatio', 'elevator', 'fiveYearsProperty', 'subway', 'district',\n",
       "       'communityAverage', 'distance', 'building_age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lat                             False\n",
       "followers                       False\n",
       "square                          False\n",
       "drawingRoom                     False\n",
       "kitchen                         False\n",
       "                                ...  \n",
       "buildingType_Plate              False\n",
       "buildingType_Tower              False\n",
       "buildingType_Tower and Plate    False\n",
       "buildingType_Unknown            False\n",
       "buildingType_nan                False\n",
       "Length: 2597, dtype: bool"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lấy những columns cần thiết để training\n",
    "train = ['Lng', 'Lat', 'tradeTime', 'followers', 'square', 'livingRoom',\n",
    "       'drawingRoom', 'kitchen', 'bathRoom', 'floor', 'buildingType',\n",
    "       'constructionTime', 'renovationCondition', 'buildingStructure',\n",
    "       'ladderRatio', 'elevator', 'fiveYearsProperty', 'subway', 'district',\n",
    "       'communityAverage', 'distance', 'building_age']\n",
    "train_data = train_data[train]\n",
    "test_data = test_data[train]\n",
    "\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "\n",
    "#obtain all the numerical features\n",
    "numerical_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "#apply standardization to each feature\n",
    "all_features[numerical_features] = all_features[numerical_features].apply( lambda x: (x-x.mean()) / x.std() )\n",
    "#replace missing values with 0\n",
    "all_features[numerical_features] = all_features[numerical_features].fillna(0)\n",
    "#one-hot encoding consider missing values as a category.\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape\n",
    "\n",
    "pd.isna(all_features).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tách dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "n_train = train_data.shape[0]\n",
    "train_features = all_features[:n_train]\n",
    "test_features = all_features[n_train:]\n",
    "train_labels = Y_train.values\n",
    "\n",
    "# Tách tập huấn luyện thành tập train và validation\n",
    "x_train, x_valid,y_train, y_valid = train_test_split(train_features, train_labels, test_size=0.250001, random_state = 27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42,n_estimators=900,max_depth=20,\n",
    "                                              n_jobs=-1,min_samples_split=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit Model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Make validation predictions\u001b[39;00m\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\App\\anacoda\\envs\\ai_class\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Make validation predictions\n",
    "\n",
    "y_pred = rf.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to 'predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Predict using RandomForest on test data\n",
    "rf_test_pred = rf.predict(test_features)\n",
    "rf_test_pred.shape\n",
    "target_predictions = rf_test_pred[:, 1]\n",
    "# Step 4: Create a DataFrame with ID and TARGET\n",
    "results_df = pd.DataFrame({\n",
    "    'ID': range(len(rf_test_pred)), \n",
    "    'TARGET': target_predictions\n",
    "})\n",
    "\n",
    "# Step 5: Export to CSV\n",
    "results_df.to_csv('predictions1.csv', index=False)\n",
    "\n",
    "print(\"Predictions have been saved to 'predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
